{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAKE NEWS CLASSIFICATION USING LSTM NEURAL NETWORK\n",
    "\n",
    "In this notebook the different stages to train a model to correctly classify fake news are performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\valen\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n",
      "(5200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_NAN(train_data, test_data):\n",
    "    train=train_data.fillna(\" \")\n",
    "    test=test_data.fillna(\" \")\n",
    "    return train, test\n",
    "\n",
    "train, test=filling_NAN(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['content']=train['title'] + \" \" + train['author']\n",
    "test['content']=test['title'] + \" \" + test['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train.drop(columns=['label'], axis=1)\n",
    "y=train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting the index\n",
    "\n",
    "messages=x.copy()\n",
    "messages_test=test.copy()\n",
    "messages.reset_index(inplace=True)\n",
    "messages_test.reset_index=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PROCESSING\n",
    "1) Remove all sequences except english ones\n",
    "2) characters are converted to lower case to avoid false predictions\n",
    "3) all sentences are tokenized into words\n",
    "4) stemming is then applied to the tokenized words\n",
    "5) words are joined together and stored in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def prepocessing(data):\n",
    "    corpus = []\n",
    "    for i in range(0,len(data)):\n",
    "        review = re.sub('[^a-zA-Z]',' ',data['content'][i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "train_corpus=prepocessing(messages)\n",
    "test_corpus=prepocessing(messages_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the words are then converted to one-hot vectors with a vocabulary size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=5000\n",
    "one_hot_train=[]\n",
    "for word in train_corpus:\n",
    "    one_hot_word=one_hot(word, vocab_size)\n",
    "    one_hot_train.append(one_hot_word)\n",
    "\n",
    "one_hot_test=[]\n",
    "for word in test_corpus:\n",
    "    one_hot_word=one_hot(word, vocab_size)\n",
    "    one_hot_test.append(one_hot_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying padding so that each sequence has the same length=20. this is done with an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length=20\n",
    "embedded_train=pad_sequences(one_hot_train, padding='pre', maxlen=total_length)\n",
    "embedded_test=pad_sequences(one_hot_test, padding='pre', maxlen=total_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 20) (20800, 20) (20800,)\n"
     ]
    }
   ],
   "source": [
    "#converting into array\n",
    "x_train_final=np.array(embedded_train)\n",
    "y_train_final=np.array(y)\n",
    "x_test_final=np.array(embedded_test)\n",
    "print(x_test_final.shape, x_train_final.shape, y_train_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the models.\n",
    "\n",
    "\n",
    "Three different models will be created and compared: logistic regression, naive bayes and LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x_train_final, y_train_final,\n",
    "                                                  train_size=0.1,\n",
    "                                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7549679487179487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR=LogisticRegression(max_iter=600)\n",
    "model_LR.fit(x_train, y_train )\n",
    "predictions_LR=model_LR.predict(x_test)\n",
    "model_LR.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      9338\n",
      "           1       0.76      0.75      0.75      9382\n",
      "\n",
      "    accuracy                           0.75     18720\n",
      "   macro avg       0.75      0.75      0.75     18720\n",
      "weighted avg       0.76      0.75      0.75     18720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_LR_report=classification_report(y_test, predictions_LR)\n",
    "print(predictions_LR)\n",
    "print(model_LR_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 1]\n",
      "0.7196047008547009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      9338\n",
      "           1       0.71      0.76      0.73      9382\n",
      "\n",
      "    accuracy                           0.72     18720\n",
      "   macro avg       0.72      0.72      0.72     18720\n",
      "weighted avg       0.72      0.72      0.72     18720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_NB=MultinomialNB()\n",
    "model_NB.fit(x_train, y_train)\n",
    "predictions_NB=model_NB.predict(x_test)\n",
    "print(predictions_NB)\n",
    "print(model_NB.score(x_test, y_test))\n",
    "model_NB_report=classification_report(y_test, predictions_NB)\n",
    "print(model_NB_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\valen\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\valen\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 40)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200)               192800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393001 (1.50 MB)\n",
      "Trainable params: 393001 (1.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_feature_vector=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_feature_vector, input_length=total_length ))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 156ms/step - loss: 0.5789 - accuracy: 0.7139 - val_loss: 0.4284 - val_accuracy: 0.8205\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 4s 128ms/step - loss: 0.2712 - accuracy: 0.8904 - val_loss: 0.2322 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 4s 128ms/step - loss: 0.1140 - accuracy: 0.9615 - val_loss: 0.1933 - val_accuracy: 0.9220\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 4s 130ms/step - loss: 0.0454 - accuracy: 0.9846 - val_loss: 0.1526 - val_accuracy: 0.9371\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 5s 142ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.1964 - val_accuracy: 0.9269\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 0.1718 - val_accuracy: 0.9365\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 4s 139ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9278\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 5s 159ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9315\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 5s 157ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1917 - val_accuracy: 0.9350\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 5s 146ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.1936 - val_accuracy: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25d29955a10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=10,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 4s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 5s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_ = np.argmax(model.predict(x_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n",
      "[[0.4993032 ]\n",
      " [0.50030386]\n",
      " [0.4988399 ]\n",
      " ...\n",
      " [0.49982983]\n",
      " [0.5010666 ]\n",
      " [0.4998441 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      9338\n",
      "           1       1.00      0.00      0.00      9382\n",
      "\n",
      "    accuracy                           0.50     18720\n",
      "   macro avg       0.75      0.50      0.33     18720\n",
      "weighted avg       0.75      0.50      0.33     18720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_report=classification_report(y_test, y_pred_, zero_division=1)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.754968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.719605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.498825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0  Logistic Regression  0.754968\n",
       "1          Naive Bayes  0.719605\n",
       "2                 LSTM  0.498825"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_LR = accuracy_score(y_test,predictions_LR)\n",
    "score_NB = accuracy_score(y_test,predictions_NB)\n",
    "score_LSTM = accuracy_score(y_test,y_pred_)\n",
    "\n",
    "results = pd.DataFrame([[\"Logistic Regression\",score_LR],[\"Naive Bayes\",score_NB],[\"LSTM\",score_LSTM]],columns=[\"Model\",\"Accuracy\"])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
